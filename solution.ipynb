{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec76b38663ea385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:48:05.228705Z",
     "start_time": "2025-11-19T14:48:05.172848Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# # AI & Security: Project 3 - Network Intrusion Detection\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# **Student Name:** [Your Name]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 1. Import Libraries\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # AI & Security: Project 3 - Network Intrusion Detection\n",
    "# **Student Name:** [Your Name]\n",
    "#\n",
    "# ## Project Overview\n",
    "# This notebook builds a Network Intrusion Detection System (NIDS) using the provided dataset.\n",
    "# We perform two classification tasks:\n",
    "# 1. **Standard Task:** Classify connections into 4 attack categories + Normal (5 classes total).\n",
    "# 2. **Advanced Task:** Predict the specific attack type (e.g., 'smurf', 'neptune').\n",
    "\n",
    "# %%\n",
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Load Data and Mappings\n",
    "# We load the connection data and the attack-to-category mapping file from the 'Data' folder.\n",
    "\n",
    "# %%\n",
    "# Define file paths\n",
    "DATA_DIR = 'Data'\n",
    "CSV_FILE = os.path.join(DATA_DIR, 'network_connections.csv')\n",
    "MAP_FILE = os.path.join(DATA_DIR, 'attack2category_map.txt')\n",
    "\n",
    "# Standard KDD Cup 99 Column Names\n",
    "# (Used if the CSV doesn't have a header. If it does, pandas will usually handle it,\n",
    "# but explicit naming ensures safety for this specific dataset).\n",
    "COL_NAMES = [\n",
    "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"\n",
    "]\n",
    "\n",
    "# --- Step A: Load the Mapping File ---\n",
    "print(f\"Loading mapping from {MAP_FILE}...\")\n",
    "attack_map = {}\n",
    "try:\n",
    "    with open(MAP_FILE, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                # Format: specific_attack category\n",
    "                # Example: 'smurf dos'\n",
    "                attack_map[parts[0]] = parts[1]\n",
    "\n",
    "    # Ensure 'normal' is in the map\n",
    "    if 'normal' not in attack_map:\n",
    "        attack_map['normal'] = 'normal'\n",
    "\n",
    "    print(f\"Successfully loaded {len(attack_map)} mappings.\")\n",
    "    print(\"Sample mapping:\", list(attack_map.items())[:5])\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Map file not found. Please check the path.\")\n",
    "\n",
    "# --- Step B: Load the Dataset ---\n",
    "print(f\"\\nLoading dataset from {CSV_FILE}...\")\n",
    "try:\n",
    "    # We assume no header based on standard KDD dumps, but if your CSV has one,\n",
    "    # change header=None to header=0 and remove names=COL_NAMES\n",
    "    df = pd.read_csv(CSV_FILE, header=None, names=COL_NAMES)\n",
    "\n",
    "    # Clean label column (remove trailing periods if they exist, e.g. 'normal.')\n",
    "    df['label'] = df['label'].astype(str).str.replace('.', '', regex=False)\n",
    "\n",
    "    print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: CSV file not found. Please check the path.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Data Preprocessing\n",
    "# * **Mapping:** Create the broad `category` column (DoS, Probe, etc.) from the specific `label`.\n",
    "# * **Encoding:** Convert text features (`protocol_type`, `service`, `flag`) to numbers.\n",
    "\n",
    "# %%\n",
    "# 1. Apply Attack Category Mapping\n",
    "df['category'] = df['label'].map(attack_map)\n",
    "\n",
    "# Fill missing categories (if any label was not in the map file)\n",
    "# We verify if any are missing\n",
    "missing_cats = df[df['category'].isna()]['label'].unique()\n",
    "if len(missing_cats) > 0:\n",
    "    print(f\"Warning: The following labels were not in the map file: {missing_cats}\")\n",
    "    df['category'] = df['category'].fillna('other')\n",
    "\n",
    "print(\"\\nClass Distribution (Categories):\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "# 2. Encode Categorical Features\n",
    "# Columns that are strings need to be turned into numbers\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "# Create a separate dataframe for processed data\n",
    "X = df.drop(['label', 'category'], axis=1)\n",
    "y_category = df['category']  # Target for Task 1\n",
    "y_specific = df['label']     # Target for Task 2 (Advanced)\n",
    "\n",
    "# Label Encoding\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# 3. Split Data\n",
    "# We use one split for both tasks to ensure fair comparison\n",
    "X_train, X_test, y_cat_train, y_cat_test, y_spec_train, y_spec_test = train_test_split(\n",
    "    X, y_category, y_specific, test_size=0.3, random_state=42, stratify=y_category\n",
    ")\n",
    "\n",
    "# 4. Scaling (Optional for Random Forest, but included for completeness)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nData Split Complete.\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_train.shape[1]}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Task 1: Standard Classification (5 Categories)\n",
    "# Build a model to classify connections as: **Normal, DoS, Probe, R2L, or U2R**.\n",
    "\n",
    "# %%\n",
    "print(\"--- Training Model for Task 1 (Categories) ---\")\n",
    "clf_cat = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf_cat.fit(X_train, y_cat_train)\n",
    "\n",
    "# Predictions\n",
    "y_cat_pred = clf_cat.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc_cat = accuracy_score(y_cat_test, y_cat_pred)\n",
    "print(f\"Task 1 Accuracy: {acc_cat:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Categories):\")\n",
    "print(classification_report(y_cat_test, y_cat_pred))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix(y_cat_test, y_cat_pred), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=clf_cat.classes_, yticklabels=clf_cat.classes_)\n",
    "plt.title('Confusion Matrix: Attack Categories')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Task 2: Advanced Classification (Specific Attacks)\n",
    "# Build a model to predict the specific attack name (e.g., 'smurf', 'warezclient').\n",
    "# **Analysis:** We will compare the accuracy of this granular model against the category model.\n",
    "\n",
    "# %%\n",
    "print(\"--- Training Model for Task 2 (Specific Attacks) ---\")\n",
    "clf_spec = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf_spec.fit(X_train, y_spec_train)\n",
    "\n",
    "# Predictions\n",
    "y_spec_pred = clf_spec.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc_spec = accuracy_score(y_spec_test, y_spec_pred)\n",
    "print(f\"Task 2 (Advanced) Accuracy: {acc_spec:.4f}\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Category Accuracy: {acc_cat:.4f}\")\n",
    "print(f\"Specific Accuracy: {acc_spec:.4f}\")\n",
    "print(f\"Difference: {acc_spec - acc_cat:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Specific Attacks - Top 15 classes):\")\n",
    "# Limiting output size since there are many classes\n",
    "report = classification_report(y_spec_test, y_spec_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose().sort_values(by='support', ascending=False).head(15)\n",
    "print(report_df)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Analysis of Results\n",
    "# * **Category Model:** Generally achieves high accuracy because the classes are broader and distinct (e.g., DoS vs Normal).\n",
    "# * **Specific Model:** May have slightly lower overall accuracy or lower recall on \"rare\" attacks (like U2R subtypes) because there are very few training examples for them compared to massive attacks like 'smurf'.\n",
    "# * **Conclusion:** While predicting the specific attack is harder, it provides much more actionable intelligence for security analysts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a25292-b96a-4662-b783-14ed40c98eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a281c-6771-4419-a39b-38dd3f4eca44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
